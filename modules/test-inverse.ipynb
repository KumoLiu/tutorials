{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load image Python extension: '/usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0rc5+4.g4f291723\n",
      "Numpy version: 1.22.2\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 4f291723c4ce1a1baf7efbd499495b777dfb1869\n",
      "MONAI __file__: /workspace/Code/MONAI/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.9.0\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.15.0a0\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.5.2\n",
      "einops version: 0.6.1\n",
      "transformers version: 4.21.3\n",
      "mlflow version: 2.3.0\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "from monai.visualize import matshow3d\n",
    "import monai.transforms as mt\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_operations(pair, every_n=10, keys=[\"image\", \"label\"]):\n",
    "    if isinstance(pair, list):\n",
    "        print(f\"metadata of patch idx 0 out of {len(pair)} samples.\\n\")\n",
    "        p_0 = pair[0]\n",
    "    else:\n",
    "        p_0 = pair\n",
    "    print(\"\\n\")\n",
    "    p_0 = p_0[\"image\"]\n",
    "    if len(p_0.shape) > 4:\n",
    "        p_0 = monai.utils.first(p_0)\n",
    "    print(f\"pixdim: {p_0.pixdim}\")\n",
    "    print(f\"shape: {p_0.shape}\")\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    matshow3d(pair[keys[0]], every_n=every_n, fig=plt.gca())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    print(pair[\"image\"].shape, pair[\"label\"].shape)\n",
    "    matshow3d(pair[keys[1]], every_n=every_n, fig=plt.gca())\n",
    "    plt.show()\n",
    "img_names = list(glob.glob(\"./totalSegmentator_mergedLabel_samples/imagesTr/*.nii.gz\"))\n",
    "seg_names = list(glob.glob(\"./totalSegmentator_mergedLabel_samples/labelsTr/*.nii.gz\"))\n",
    "datalist = [{\"image\": _img_name, \"label\": _seg_name} for _img_name, _seg_name in zip(img_names, seg_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.utils.set_determinism(24)\n",
    "both_keys = [\"image\", \"label\"]\n",
    "transform_list_lazy = [\n",
    "        mt.LoadImaged(keys=both_keys, image_only=True, ensure_channel_first=True),\n",
    "        mt.EnsureTyped(keys=both_keys),\n",
    "        mt.Orientationd(keys=both_keys, axcodes=\"RAS\"),\n",
    "        mt.Spacingd(keys=both_keys, pixdim=(3.0, 3.0, 3.0), mode=[\"bilinear\", \"nearest\"]),\n",
    "        # mt.Identityd(keys=[\"image\"]),\n",
    "        # mt.NormalizeIntensityd(keys=[\"image\"], nonzero=True),\n",
    "        # mt.CropForegroundd(keys=both_keys, source_key=\"image\", margin=10, k_divisible=[96, 96, 96]),\n",
    "        # mt.GaussianSmoothd(keys=[\"image\"], sigma=0.4),\n",
    "        # mt.ScaleIntensityd(keys=[\"image\"], minv=-1.0, maxv=1.0),\n",
    "]\n",
    "\n",
    "\n",
    "xform = mt.Compose(\n",
    "    transform_list_lazy, lazy_evaluation=False, override_keys=(\"image\", \"label\"), overrides={\"mode\": (\"bilinear\", \"nearest\"), 'padding_mode': ('border', 'zeros'), 'dtype': torch.float32}\n",
    ")\n",
    "xform_inverse = mt.Compose(\n",
    "    transform_list_lazy, lazy_evaluation=False, override_keys=(\"image\", \"label\"), overrides={\"mode\": (\"bilinear\", \"nearest\"), 'padding_mode': ('border', 'zeros'), 'dtype': torch.float32}\n",
    ")\n",
    "\n",
    "def net_identity(data):\n",
    "    return mt.AsDiscrete(to_onehot=105)(data.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "infer = SlidingWindowInferer(roi_size=[96, 96, 96], sw_batch_size=1, overlap=0.25)\n",
    "\n",
    "data = datalist[1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-processing: torch.Size([1, 130, 130, 142])\n",
      "After infer: torch.Size([105, 130, 130, 142])\n",
      "After inverse: torch.Size([1, 259, 259, 283]) torch.Size([1, 259, 259, 283])\n"
     ]
    }
   ],
   "source": [
    "post_trans_v1 = mt.Compose([\n",
    "    mt.Invertd(keys=[\"pred\", \"label\"], transform=xform_inverse, orig_keys=\"image\", nearest_interp=True, to_tensor=True),\n",
    "    mt.AsDiscreted(keys=\"pred\", argmax=True),\n",
    "])\n",
    "out_v1 = xform(data)\n",
    "print('After pre-processing:', out_v1[0][\"label\"].shape)\n",
    "\n",
    "out_v1[0][\"pred\"] = infer(out_v1[0][\"label\"].unsqueeze(0), network=net_identity).squeeze(0)\n",
    "print('After infer:', out_v1[0][\"pred\"].shape)\n",
    "out_v1_post = post_trans_v1(out_v1[0])\n",
    "print(\"After inverse:\", out_v1_post[\"pred\"].shape, out_v1_post[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-processing: torch.Size([1, 130, 130, 142])\n",
      "After infer: torch.Size([105, 130, 130, 142])\n",
      "After inverse: torch.Size([1, 259, 259, 283])\n"
     ]
    }
   ],
   "source": [
    "post_trans_v2 = mt.Compose([\n",
    "    mt.AsDiscreted(keys=\"pred\", argmax=True),\n",
    "    mt.Invertd(keys=[\"pred\", \"label\"], transform=xform_inverse, orig_keys=\"image\", nearest_interp=True, to_tensor=True),\n",
    "])\n",
    "\n",
    "out_v2 = xform(data)\n",
    "print('After pre-processing:', out_v2[0][\"label\"].shape)\n",
    "def net_identity(data):\n",
    "    return mt.AsDiscrete(to_onehot=105)(data.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "infer = SlidingWindowInferer(roi_size=[96, 96, 96], sw_batch_size=1, overlap=0.25)\n",
    "out_v2[0][\"pred\"] = infer(out_v2[0][\"label\"].unsqueeze(0), network=net_identity).squeeze(0)\n",
    "print('After infer:', out_v2[0][\"pred\"].shape)\n",
    "out_v2_post = post_trans_v2(out_v2[0])\n",
    "print(\"After inverse:\", out_v2_post[\"pred\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = mt.LoadImaged(keys=both_keys, image_only=True, ensure_channel_first=True)(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "metric = DiceMetric(include_background=False, num_classes=105)\n",
    "metric(out_v1_post[\"pred\"].unsqueeze(0), out_v2_post[\"pred\"].unsqueeze(0))\n",
    "_metric = metric.aggregate().item()\n",
    "metric.reset()\n",
    "print(_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8830903172492981\n"
     ]
    }
   ],
   "source": [
    "metric = DiceMetric(include_background=False, num_classes=105)\n",
    "metric(out_v1_post[\"pred\"].unsqueeze(0), data_raw[\"label\"].unsqueeze(0))\n",
    "_metric = metric.aggregate().item()\n",
    "metric.reset()\n",
    "print(_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
